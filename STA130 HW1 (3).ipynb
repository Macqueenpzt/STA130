{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "032ec1a6-5474-48d9-8031-7cc6a5dec801",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#               0\n",
      "Name            0\n",
      "Type 1          0\n",
      "Type 2        386\n",
      "HP              0\n",
      "Attack          0\n",
      "Defense         0\n",
      "Sp. Atk         0\n",
      "Sp. Def         0\n",
      "Speed           0\n",
      "Generation      0\n",
      "Legendary       0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#1.\n",
    "import pandas as pd \n",
    "\n",
    "# Load the dataset from the URL\n",
    "url = \"https://raw.githubusercontent.com/KeithGalli/pandas/master/pokemon_data.csv\"\n",
    "df = pd.read_csv(url)\n",
    "\n",
    "# Get the count of missing values for each column\n",
    "missing_counts = df.isnull().sum()\n",
    "\n",
    "# Output the missing values count\n",
    "print(missing_counts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6b584a19-e7a3-4e63-8a95-a006edd76ba1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows: 800\n",
      "Number of columns: 12\n"
     ]
    }
   ],
   "source": [
    "#2.(1)\n",
    "# Get the number of rows and columns\n",
    "num_rows, num_columns = df.shape\n",
    "\n",
    "# Output the number of rows\n",
    "print(f\"Number of rows: {num_rows}\")\n",
    "print(f\"Number of columns: {num_columns}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0878ca71",
   "metadata": {},
   "source": [
    "2.(2)Observations imply the rows of the Dataframe or Series in pandas. Variables imply the columns of the Dataframe or Series in pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c4aa2831-b3b6-454f-b940-4f9f7cc4f5b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary statistics for numeric columns:\n",
      "                #          HP      Attack     Defense     Sp. Atk     Sp. Def  \\\n",
      "count  800.000000  800.000000  800.000000  800.000000  800.000000  800.000000   \n",
      "mean   362.813750   69.258750   79.001250   73.842500   72.820000   71.902500   \n",
      "std    208.343798   25.534669   32.457366   31.183501   32.722294   27.828916   \n",
      "min      1.000000    1.000000    5.000000    5.000000   10.000000   20.000000   \n",
      "25%    184.750000   50.000000   55.000000   50.000000   49.750000   50.000000   \n",
      "50%    364.500000   65.000000   75.000000   70.000000   65.000000   70.000000   \n",
      "75%    539.250000   80.000000  100.000000   90.000000   95.000000   90.000000   \n",
      "max    721.000000  255.000000  190.000000  230.000000  194.000000  230.000000   \n",
      "\n",
      "            Speed  Generation  \n",
      "count  800.000000   800.00000  \n",
      "mean    68.277500     3.32375  \n",
      "std     29.060474     1.66129  \n",
      "min      5.000000     1.00000  \n",
      "25%     45.000000     2.00000  \n",
      "50%     65.000000     3.00000  \n",
      "75%     90.000000     5.00000  \n",
      "max    180.000000     6.00000  \n"
     ]
    }
   ],
   "source": [
    "#3\n",
    "# Get summary statistics for numeric columns\n",
    "summary_statistics = df.describe()\n",
    "\n",
    "print(\"Summary statistics for numeric columns:\")\n",
    "print(summary_statistics)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b9dcabc",
   "metadata": {},
   "source": [
    "4.The results generated by df.shape calculate the total number of columns of our dataset. And the results generated by df.describe() only calculate the number of numetric columns in our dataset, it doesn't summarize those non-numetric columns. However, there are non-numetric columns exist in our dataset, therefore these two results are different, the number of columns of dataset generated by df.shape might be more than the number of columns of dataset generated by df.describe().\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2edf2f53",
   "metadata": {},
   "source": [
    "5.According to Chatbot, \"attribute\" is a variable that stores data about an object. It's a characteristic or property of an object, we access it directly without coding parentheses. And \"method\" is a function that belongs to an object, it defines an action that the object can perform. In my own understanding, \"attribute\" imports the charactiristics of an object and we do not need to use () to input, and \"method\"means that executing specific sperations on the obiect, so we need () to input.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a200fb74",
   "metadata": {},
   "source": [
    "6.df.describe() is used to generate specific and meaningful statistical data of the Dataframe, which means that it only calculates numerical variables rather than non-numeric variables, this is beacause mean, std and so on can only work for numbers, so df.describe() only analyze the numeric variables in the Dataframe. df.describe() provides us with numerous statistics, here are the explanations of these statistics.\n",
    "count:the quantity of those variables that have values in each columns.\n",
    "\n",
    "mean:the average value of numerical variables in each columns. \n",
    "\n",
    "std:standard deviation,s is equal to the square root of sample variance, it shows how spread out the values are from the mean. \n",
    "\n",
    "min:The minimum value in each column. \n",
    "\n",
    "25%:The value below which 25% of the Dataframe. \n",
    "\n",
    "50%:The median value. \n",
    "\n",
    "75%:The value below which 75% of the Daraframe. \n",
    "\n",
    "max:The maximum value in each column. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a03f487d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Name  Height  Weight\n",
      "0    A   180.0    85.0\n",
      "1    B     NaN     NaN\n",
      "2    C   175.0    75.0\n"
     ]
    }
   ],
   "source": [
    "#7.(1)When we wanna delete a row that contains NaN rather than delete the whole column, we prefer using df.dropna(). Here is an example.\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame({'Name':['A','B','C'], 'Height':[180,None,175], 'Weight':[85,None,75]})\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "28b5200b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Name  Height  Weight\n",
      "0    A   180.0    85.0\n",
      "2    C   175.0    75.0\n"
     ]
    }
   ],
   "source": [
    "#if we wanna delete the row1 rather than delete the whole column, we can use df.dropna().\n",
    "print(df.dropna())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd34b015",
   "metadata": {},
   "source": [
    "I think in this kind of situation, we'd better prefer using df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "195cbaea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Name  Height  Weight\n",
      "0    A     180      85\n",
      "1    B     187      92\n",
      "2    C     175      75\n",
      "  Name  Height\n",
      "0    A     180\n",
      "1    B     187\n",
      "2    C     175\n"
     ]
    }
   ],
   "source": [
    "#7.(2) If we wannna delete a whole column permanantly, we prefer using del df['col'].\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame({'Name':['A','B','C'], 'Height':[180,187,175], 'Weight':[85,92,75]})\n",
    "print(df)\n",
    "#For example, if we don't need the data of weight, we use df['col'] to delete the 'Weight' column.\n",
    "del df['Weight']\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "afb49614",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Name  Height  Weight\n",
      "1    B   187.0      92\n",
      "2    C   175.0      75\n"
     ]
    }
   ],
   "source": [
    "#7.(3)If we wanna delete the data that is unnessary and delete the rows or columns that contain missing values, we use del df['col'] first. \n",
    "#If we first use df.dropna(), it will delete the rows that contain missing values, \n",
    "#which might lead to that our useful data might be deleted at the same time. Here is a example.\n",
    "import pandas as pd\n",
    "df = pd.DataFrame({'Name':['A','B','C'], 'Height':[None,187,175], 'Weight':[85,92,75], 'Age':[30, 40, None]})\n",
    "#assume that we don't need data of age, we only need data of 'Name', 'Height' and 'Weight'\n",
    "del df['Age']\n",
    "print(df.dropna())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "015149d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Name  Height  Weight   Age\n",
      "1    B   187.0      92  40.0\n"
     ]
    }
   ],
   "source": [
    "#If we use df.dropna() first\n",
    "import pandas as pd\n",
    "df = pd.DataFrame({'Name':['A','B','C'], 'Height':[None,187,175], 'Weight':[85,92,75], 'Age':[30, 40, None]})\n",
    "print(df.dropna())\n",
    "del df['Age']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f3e65dd",
   "metadata": {},
   "source": [
    "The output result shows that some important data were deleted togather, we lost the data of Height and Weight of C, so if we wanna delete the data that is unnessary and delete the rows or columns that contain missing values, we use del df['col'] first."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d297c4cb",
   "metadata": {},
   "source": [
    "7.(4)The approach for removing misssing data from the dataset.\n",
    "Step1: Generating the DataFrame and identify which data we want to remove.\n",
    "Step2: Using del df['col'] to delete the columns whose data is not useful for our analysis.\n",
    "Step3: Using df.dropna() to delete the rows and columns which contain missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9b58cb57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 15 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   survived     891 non-null    int64  \n",
      " 1   pclass       891 non-null    int64  \n",
      " 2   sex          891 non-null    object \n",
      " 3   age          714 non-null    float64\n",
      " 4   sibsp        891 non-null    int64  \n",
      " 5   parch        891 non-null    int64  \n",
      " 6   fare         891 non-null    float64\n",
      " 7   embarked     889 non-null    object \n",
      " 8   class        891 non-null    object \n",
      " 9   who          891 non-null    object \n",
      " 10  adult_male   891 non-null    bool   \n",
      " 11  deck         203 non-null    object \n",
      " 12  embark_town  889 non-null    object \n",
      " 13  alive        891 non-null    object \n",
      " 14  alone        891 non-null    bool   \n",
      "dtypes: bool(2), float64(2), int64(4), object(7)\n",
      "memory usage: 92.4+ KB\n",
      "None\n",
      "         survived      pclass         age       sibsp       parch        fare\n",
      "count  891.000000  891.000000  714.000000  891.000000  891.000000  891.000000\n",
      "mean     0.383838    2.308642   29.699118    0.523008    0.381594   32.204208\n",
      "std      0.486592    0.836071   14.526497    1.102743    0.806057   49.693429\n",
      "min      0.000000    1.000000    0.420000    0.000000    0.000000    0.000000\n",
      "25%      0.000000    2.000000   20.125000    0.000000    0.000000    7.910400\n",
      "50%      0.000000    3.000000   28.000000    0.000000    0.000000   14.454200\n",
      "75%      1.000000    3.000000   38.000000    1.000000    0.000000   31.000000\n",
      "max      1.000000    3.000000   80.000000    8.000000    6.000000  512.329200\n",
      "survived         0\n",
      "pclass           0\n",
      "sex              0\n",
      "age            177\n",
      "sibsp            0\n",
      "parch            0\n",
      "fare             0\n",
      "embarked         2\n",
      "class            0\n",
      "who              0\n",
      "adult_male       0\n",
      "deck           688\n",
      "embark_town      2\n",
      "alive            0\n",
      "alone            0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#8.\n",
    "import pandas as pd\n",
    "\n",
    "# Load the Titanic dataset\n",
    "url = \"https://raw.githubusercontent.com/mwaskom/seaborn-data/master/titanic.csv\"\n",
    "df = pd.read_csv(url)\n",
    "\n",
    "# View basic info to identify missing data\n",
    "print(df.info())\n",
    "\n",
    "# Summary statistics for numeric columns\n",
    "print(df.describe())\n",
    "\n",
    "# Count of missing values per column\n",
    "print(df.isna().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3db44841",
   "metadata": {},
   "source": [
    "8.(1)According to ChatGPT, df.groupby(\"col1\")[\"col2\"].describe() function groups the DataFrame by the values in col1 and provides a summary of descriptive statistics for col2 within each group. These statistics typically include:count, mean, std, min, max, 25%, 50% and 75%. Here is an example of using df.groupby(\"col1\")[\"col2\"].describe().\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "24002d5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Letter  Number\n",
      "0      A       5\n",
      "1      A       9\n",
      "2      A       1\n",
      "3      A       3\n",
      "4      B       5\n",
      "5      B      15\n",
      "6      C       7\n",
      "7      C       9\n",
      "        count  mean       std  min  25%   50%   75%   max\n",
      "Letter                                                   \n",
      "A         4.0   4.5  3.415650  1.0  2.5   4.0   6.0   9.0\n",
      "B         2.0  10.0  7.071068  5.0  7.5  10.0  12.5  15.0\n",
      "C         2.0   8.0  1.414214  7.0  7.5   8.0   8.5   9.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "Data = {'Letter':['A','A','A','A','B','B','C','C' ], 'Number':[5,9,1,3,5,15,7,9]}\n",
    "df = pd.DataFrame(Data)\n",
    "print(df)\n",
    "df1 = df.groupby(\"Letter\")[\"Number\"].describe()\n",
    "print(df1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fbfd4fb",
   "metadata": {},
   "source": [
    "Here is my understanding. First, we group the DataFrame by the column 'Letter', which means that we put the obiects that are same in the column 'Letter' in a group, we put 'A' in one group and put 'B' and 'C' in other two different groups. Then we use df.describe() function to analyze statistics for each group. For example, we obtain that the mean of group 'A' is 4.5, and the min of group 'B' is 5.0. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3d4e4bd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Height     Weight        Age\n",
      "count    2.000000   3.000000   2.000000\n",
      "mean   181.000000  84.000000  35.000000\n",
      "std      8.485281   8.544004   7.071068\n",
      "min    175.000000  75.000000  30.000000\n",
      "25%    178.000000  80.000000  32.500000\n",
      "50%    181.000000  85.000000  35.000000\n",
      "75%    184.000000  88.500000  37.500000\n",
      "max    187.000000  92.000000  40.000000\n"
     ]
    }
   ],
   "source": [
    "#8.(2)Here is the DataFrame I use in question7\n",
    "import pandas as pd\n",
    "df = pd.DataFrame({'Name':['A','B','C'], 'Height':[None,187,175], 'Weight':[85,92,75], 'Age':[30, 40, None]})\n",
    "print(df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b43182d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Letter  Number\n",
      "0      A       5\n",
      "1      A       9\n",
      "2      A       1\n",
      "3      A       3\n",
      "4      B       5\n",
      "5      B      15\n",
      "6      C       7\n",
      "7      C       9\n",
      "        count  mean       std  min  25%   50%   75%   max\n",
      "Letter                                                   \n",
      "A         4.0   4.5  3.415650  1.0  2.5   4.0   6.0   9.0\n",
      "B         2.0  10.0  7.071068  5.0  7.5  10.0  12.5  15.0\n",
      "C         2.0   8.0  1.414214  7.0  7.5   8.0   8.5   9.0\n"
     ]
    }
   ],
   "source": [
    "#Here is the DataFrame I use in question8(1)\n",
    "import pandas as pd\n",
    "df = pd.DataFrame({'Letter':['A','A','A','A','B','B','C','C' ], 'Number':[5,9,1,3,5,15,7,9]})\n",
    "print(df)\n",
    "print(df.groupby('Letter')['Number'].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d128f982",
   "metadata": {},
   "source": [
    "Count generated by df.describe() is the quantity of non-null values of each columns in the whole DataFrame. Since we use df.groupby('col1')['col2].describe() to group the DataFrame, so count generated by df.groupby('col1')['col2'].describe() is the quantity of non-null values in each group."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60ae3dc3",
   "metadata": {},
   "source": [
    "8.(3)If we wanna find out and then fix the errors, it's better use Chatbot since it can point out the errors more directly and accurately and can also provide users with solution. But if wanna learn more knowledge, we can use google search, since it provides us with a number of solutions, so we can expose to the code, functions, attribute that we might haven't seen before. However, some solutions in Google search might be wrong, so we ought to recgonize whether the solution is correct, and then choose the correct solutions and learn from it.\n",
    "\n",
    "8(3)A.Chatbot: The NameError indicates that pd hasn't been defined, which usually means you haven't imported Pandas.\n",
    "You can fix this error by importing Pandas at the beginning of your script or notebook. Add this line: \n",
    "import pandas as pd\n",
    "This will allow you to use pd as an alias for Pandas throughout your code.\n",
    "\n",
    "Google search:Google search provides me with two examples, the first one is as same as what Chatbot tells me, we can add this line:import pandas as pd at the beginning. And the second example is add this line: import pandas.\n",
    "\n",
    "In quesionA, Chatbot provides the troubleshooting help more quickly and directly, and Google search give me more solutions.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2c6cf41b",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'titanics.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Load the Titanic dataset\u001b[39;00m\n\u001b[1;32m      4\u001b[0m url \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtitanics.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 5\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/pandas/io/parsers/readers.py:948\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m    935\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    936\u001b[0m     dialect,\n\u001b[1;32m    937\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    944\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m    945\u001b[0m )\n\u001b[1;32m    946\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 948\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/pandas/io/parsers/readers.py:611\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    608\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    610\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 611\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    613\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    614\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1448\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1445\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1447\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1448\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1705\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1703\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1704\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1705\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1706\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1707\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1708\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1709\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1710\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1711\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1712\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1713\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1714\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1715\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1716\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/pandas/io/common.py:863\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    858\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    859\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    860\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    861\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    862\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 863\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    864\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    865\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    866\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    867\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    868\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    869\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    870\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    871\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    872\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'titanics.csv'"
     ]
    }
   ],
   "source": [
    "#8(3)B. Mistype \"titanic.csv\" as \"titanics.csv\"\n",
    "import pandas as pd\n",
    "\n",
    "# Load the Titanic dataset\n",
    "url = \"titanics.csv\"\n",
    "df = pd.read_csv(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be604a7a",
   "metadata": {},
   "source": [
    "In questionB, ChatGPT offers a step-by-step guide and code.1. Check File Path.2. Verify File Name.3. Current Working Directory.4. File Existence.5. Permissions. Google search gives many whole solutions, it can help us learn but it requires time and high-level knowledge."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "da2a3802",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Letter  Number\n",
      "0      A       5\n",
      "1      A       9\n",
      "2      A       1\n",
      "3      A       3\n",
      "4      B       5\n",
      "5      B      15\n",
      "6      C       7\n",
      "7      C       9\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'DF' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame({\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLetter\u001b[39m\u001b[38;5;124m'\u001b[39m:[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mA\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mA\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mA\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mA\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mB\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mB\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mC\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mC\u001b[39m\u001b[38;5;124m'\u001b[39m ], \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNumber\u001b[39m\u001b[38;5;124m'\u001b[39m:[\u001b[38;5;241m5\u001b[39m,\u001b[38;5;241m9\u001b[39m,\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m3\u001b[39m,\u001b[38;5;241m5\u001b[39m,\u001b[38;5;241m15\u001b[39m,\u001b[38;5;241m7\u001b[39m,\u001b[38;5;241m9\u001b[39m]})\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(df)\n\u001b[0;32m----> 5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mDF\u001b[49m\u001b[38;5;241m.\u001b[39mgroupby(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLetter\u001b[39m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNumber\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mdescribe())\n",
      "\u001b[0;31mNameError\u001b[0m: name 'DF' is not defined"
     ]
    }
   ],
   "source": [
    "#8(3)C. Try to use a dataframe before it's been assigned into the variable\n",
    "import pandas as pd\n",
    "df = pd.DataFrame({'Letter':['A','A','A','A','B','B','C','C' ], 'Number':[5,9,1,3,5,15,7,9]})\n",
    "print(df)\n",
    "print(DF.groupby('Letter')['Number'].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "edfb86b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Letter  Number\n",
      "0      A       5\n",
      "1      A       9\n",
      "2      A       1\n",
      "3      A       3\n",
      "4      B       5\n",
      "5      B      15\n",
      "6      C       7\n",
      "7      C       9\n",
      "        count  mean       std  min  25%   50%   75%   max\n",
      "Letter                                                   \n",
      "A         4.0   4.5  3.415650  1.0  2.5   4.0   6.0   9.0\n",
      "B         2.0  10.0  7.071068  5.0  7.5  10.0  12.5  15.0\n",
      "C         2.0   8.0  1.414214  7.0  7.5   8.0   8.5   9.0\n"
     ]
    }
   ],
   "source": [
    "#Here is the answer from ChatGPT\n",
    "#It looks like there's a typo in your code. You used DF.groupby() instead of df.groupby(). Here's the corrected version of your code\n",
    "import pandas as pd\n",
    "df = pd.DataFrame({'Letter': ['A', 'A', 'A', 'A', 'B', 'B', 'C', 'C'],\n",
    "                   'Number': [5, 9, 1, 3, 5, 15, 7, 9]})\n",
    "print(df)\n",
    "\n",
    "# Grouping by 'Letter' and describing the 'Number'\n",
    "print(df.groupby('Letter')['Number'].describe())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa6067a9",
   "metadata": {},
   "source": [
    "This error is due to a simple typing mistake, it is more quickly to ask ChatGPT to fix it, no need to search it on Google."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b8456364",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "incomplete input (1273277452.py, line 4)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[9], line 4\u001b[0;36m\u001b[0m\n\u001b[0;31m    print(df.shape\u001b[0m\n\u001b[0m                  ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m incomplete input\n"
     ]
    }
   ],
   "source": [
    "#8(3)D. Forget one of the parentheses somewhere the code\n",
    "import pandas as pd\n",
    "df = pd.DataFrame({'A':[1,2.5,50,31], 'B':[34,5,8,100]})\n",
    "print(df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "03e436ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 2)\n"
     ]
    }
   ],
   "source": [
    "#Here is the answer from ChatGPT\n",
    "import pandas as pd\n",
    "df = pd.DataFrame({'A': [1, 2.5, 50, 31], 'B': [34, 5, 8, 100]})\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb3acab3",
   "metadata": {},
   "source": [
    "This question is quite similar to the last one, the reason why this error occurs is a simple typing mistake, so it is more quickly to ask ChatGPT to fix it, no need to search it on Google."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9d3b423a",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'group_by'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_52/1373187190.py\u001b[0m in \u001b[0;36m?\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m df = pd.DataFrame({'Letter': ['A', 'A', 'A', 'A', 'B', 'B', 'C', 'C'],\n\u001b[1;32m      4\u001b[0m                    'Number': [5, 9, 1, 3, 5, 15, 7, 9]})\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Grouping by 'Letter' and describing the 'Number'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroup_by\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Letter'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Number'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdescribe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# df.group_by(\"col1\")[\"col2\"].describe() and df.groupby(\"col1\")[\"col2\"].describle()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.11/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   6200\u001b[0m             \u001b[0;32mand\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_accessors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6201\u001b[0m             \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6202\u001b[0m         ):\n\u001b[1;32m   6203\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6204\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'group_by'"
     ]
    }
   ],
   "source": [
    "#8(3)E. Mistype one of the names of the chained functions with the code\n",
    "import pandas as pd\n",
    "df = pd.DataFrame({'Letter': ['A', 'A', 'A', 'A', 'B', 'B', 'C', 'C'],\n",
    "                   'Number': [5, 9, 1, 3, 5, 15, 7, 9]})\n",
    "# Grouping by 'Letter' and describing the 'Number'\n",
    "print(df.group_by('Letter')['Number'].describe()) # df.group_by(\"col1\")[\"col2\"].describe() and df.groupby(\"col1\")[\"col2\"].describle()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28aad00a",
   "metadata": {},
   "source": [
    "This is just a syntax issue, using ChatGPT to fix it might be more faster than Google."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6481e0ef",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'letter'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m      3\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame({\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLetter\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mA\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mA\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mA\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mA\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mB\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mB\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mC\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mC\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m      4\u001b[0m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNumber\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;241m5\u001b[39m, \u001b[38;5;241m9\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m5\u001b[39m, \u001b[38;5;241m15\u001b[39m, \u001b[38;5;241m7\u001b[39m, \u001b[38;5;241m9\u001b[39m]})\n\u001b[0;32m----> 5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroupby\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mletter\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNumber\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mdescribe()) \u001b[38;5;66;03m#replace 'Letter' with 'letter'\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/pandas/core/frame.py:8869\u001b[0m, in \u001b[0;36mDataFrame.groupby\u001b[0;34m(self, by, axis, level, as_index, sort, group_keys, observed, dropna)\u001b[0m\n\u001b[1;32m   8866\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m level \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m by \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   8867\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou have to supply one of \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mby\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m and \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlevel\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 8869\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mDataFrameGroupBy\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   8870\u001b[0m \u001b[43m    \u001b[49m\u001b[43mobj\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   8871\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkeys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mby\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   8872\u001b[0m \u001b[43m    \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   8873\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   8874\u001b[0m \u001b[43m    \u001b[49m\u001b[43mas_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mas_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   8875\u001b[0m \u001b[43m    \u001b[49m\u001b[43msort\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   8876\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgroup_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   8877\u001b[0m \u001b[43m    \u001b[49m\u001b[43mobserved\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mobserved\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   8878\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdropna\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdropna\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   8879\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/pandas/core/groupby/groupby.py:1278\u001b[0m, in \u001b[0;36mGroupBy.__init__\u001b[0;34m(self, obj, keys, axis, level, grouper, exclusions, selection, as_index, sort, group_keys, observed, dropna)\u001b[0m\n\u001b[1;32m   1275\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropna \u001b[38;5;241m=\u001b[39m dropna\n\u001b[1;32m   1277\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m grouper \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1278\u001b[0m     grouper, exclusions, obj \u001b[38;5;241m=\u001b[39m \u001b[43mget_grouper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1279\u001b[0m \u001b[43m        \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1280\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkeys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1281\u001b[0m \u001b[43m        \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1282\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1283\u001b[0m \u001b[43m        \u001b[49m\u001b[43msort\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1284\u001b[0m \u001b[43m        \u001b[49m\u001b[43mobserved\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobserved\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mno_default\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobserved\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1285\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdropna\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropna\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1286\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1288\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m observed \u001b[38;5;129;01mis\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mno_default:\n\u001b[1;32m   1289\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28many\u001b[39m(ping\u001b[38;5;241m.\u001b[39m_passed_categorical \u001b[38;5;28;01mfor\u001b[39;00m ping \u001b[38;5;129;01min\u001b[39;00m grouper\u001b[38;5;241m.\u001b[39mgroupings):\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/pandas/core/groupby/grouper.py:1009\u001b[0m, in \u001b[0;36mget_grouper\u001b[0;34m(obj, key, axis, level, sort, observed, validate, dropna)\u001b[0m\n\u001b[1;32m   1007\u001b[0m         in_axis, level, gpr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m, gpr, \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1008\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1009\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(gpr)\n\u001b[1;32m   1010\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(gpr, Grouper) \u001b[38;5;129;01mand\u001b[39;00m gpr\u001b[38;5;241m.\u001b[39mkey \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1011\u001b[0m     \u001b[38;5;66;03m# Add key to exclusions\u001b[39;00m\n\u001b[1;32m   1012\u001b[0m     exclusions\u001b[38;5;241m.\u001b[39madd(gpr\u001b[38;5;241m.\u001b[39mkey)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'letter'"
     ]
    }
   ],
   "source": [
    "#8(3)F. Use a column name that's not in your data for the groupby and column selection\n",
    "import pandas as pd\n",
    "df = pd.DataFrame({'Letter': ['A', 'A', 'A', 'A', 'B', 'B', 'C', 'C'],\n",
    "'Number': [5, 9, 1, 3, 5, 15, 7, 9]})\n",
    "print(df.groupby('letter')['Number'].describe()) #replace 'Letter' with 'letter'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5e46a7e",
   "metadata": {},
   "source": [
    "According to ChatGPT, column names are case-sensitive, so groupby('Letter') needs to match exactly how the column is named in the DataFrame.\n",
    "It is similar to the previous one, ChatGPT can quickly spot the keyerror, it is faster than Google."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d6a16703",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Letter' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m      3\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame({\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLetter\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mA\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mA\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mA\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mA\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mB\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mB\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mC\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mC\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m      4\u001b[0m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNumber\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;241m5\u001b[39m, \u001b[38;5;241m9\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m5\u001b[39m, \u001b[38;5;241m15\u001b[39m, \u001b[38;5;241m7\u001b[39m, \u001b[38;5;241m9\u001b[39m]})\n\u001b[0;32m----> 5\u001b[0m \u001b[38;5;28mprint\u001b[39m(df\u001b[38;5;241m.\u001b[39mgroupby(\u001b[43mLetter\u001b[49m)[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNumber\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mdescribe()) \n",
      "\u001b[0;31mNameError\u001b[0m: name 'Letter' is not defined"
     ]
    }
   ],
   "source": [
    "#8(3)G. Forget to put the column name as a string in quotes for the groupby and column selection.\n",
    "import pandas as pd\n",
    "df = pd.DataFrame({'Letter': ['A', 'A', 'A', 'A', 'B', 'B', 'C', 'C'],\n",
    "'Number': [5, 9, 1, 3, 5, 15, 7, 9]})\n",
    "print(df.groupby(Letter)['Number'].describe()) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bb3a171",
   "metadata": {},
   "source": [
    "The error in your code is that Letter should be in quotes because it's the name of a column in the DataFrame. Without quotes, Python interprets Letter as a variable, which isn't defined.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7547eda",
   "metadata": {},
   "source": [
    "In summary, I think ChatGPT provides the necessary toubleshooting help more quickly than Google search.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c949276c",
   "metadata": {},
   "source": [
    "9. Yes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4f0157b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
